{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "import scipy.misc\n",
    "from scipy import ndimage\n",
    "\n",
    "from datasets import dataset_utils\n",
    "\n",
    "from datasets import imagenet\n",
    "from nets import inception\n",
    "from preprocessing import inception_preprocessing\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(data,img_size):\n",
    "    res_img = []\n",
    "    for i in range(len(data)):\n",
    "        res_img.append(imresize(data[i],[img_size,img_size]))\n",
    "    return res_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = np.array(mpimg.imread(os.path.join(folder,filename)))\n",
    "        images.append(img)\n",
    "\n",
    "    images = preprocess_images(images,image_size)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Downloading inception_v3_2016_08_28.tar.gz 100.0%\n",
      "Successfully downloaded inception_v3_2016_08_28.tar.gz 100885009 bytes.\n"
     ]
    }
   ],
   "source": [
    "from datasets import dataset_utils\n",
    "import tensorflow as tf\n",
    "\n",
    "url = \"http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\"\n",
    "checkpoints_dir = '/tmp/checkpoints'\n",
    "if not tf.gfile.Exists(checkpoints_dir):\n",
    "    tf.gfile.MakeDirs(checkpoints_dir)\n",
    "\n",
    "dataset_utils.download_and_uncompress_tarball(url, checkpoints_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "image_size = inception.inception_v3.default_image_size\n",
    "image=tf.placeholder(dtype='float32',shape=[None,image_size,image_size,3])\n",
    "\n",
    "with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "    logits, layers_list = inception.inception_v3(image, num_classes=1001, is_training=False)\n",
    "\n",
    "vector = layers_list.get('PreLogits',None)\n",
    "\n",
    "init_fn = slim.assign_from_checkpoint_fn(\n",
    "            os.path.join(checkpoints_dir, 'inception_v3.ckpt'),\n",
    "            slim.get_model_variables())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "X1 = load_images_from_folder('/Users/Vard/Downloads/flowers/rose')\n",
    "y1 = np.array([0]*X1.shape[0])\n",
    "X2 = load_images_from_folder('/Users/Vard/Downloads/flowers/tulip')\n",
    "y2 = np.array([0]*X2.shape[0])\n",
    "X = np.vstack([X1,X2])\n",
    "y = np.hstack([y1,y2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/checkpoints/inception_v3.ckpt\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[0]\n",
    "n_batch = 4\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    init_fn(sess)\n",
    "    vectors = np.array([])\n",
    "\n",
    "    rng_minibatches = range(0, n - n_batch + 1, n_batch)\n",
    "    for start_idx in rng_minibatches:\n",
    "        X_batch = X[start_idx:(start_idx+n_batch),:]\n",
    "        [vector_val] = sess.run([vector],feed_dict={image:X_batch})\n",
    "        if start_idx == 0:\n",
    "            vectors = np.squeeze(vector_val)\n",
    "        else:\n",
    "            vectors = np.vstack([vectors, np.squeeze(vector_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans best score is 0.5124434389140271\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cluster\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "two_means = cluster.KMeans(n_clusters= 2)\n",
    "parameters = {'n_init': range(2,15)}\n",
    "clf = GridSearchCV(two_means,parameters)\n",
    "clf.fit(vectors)\n",
    "\n",
    "n_init = clf.best_params_['n_init']\n",
    "two_means = cluster.KMeans(n_clusters= 2,n_init= n_init).fit(vectors)\n",
    "acc1 = np.mean(np.equal(two_means.labels_, y))\n",
    "\n",
    "print('KMeans best score is',acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/manifold/spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral score is 0.998868778280543\n"
     ]
    }
   ],
   "source": [
    "spectral = cluster.SpectralClustering(n_clusters=2).fit(vectors)\n",
    "acc2 = np.mean(np.equal(spectral.labels_, y))\n",
    "print('Spectral score is',acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN score is 0.0005656108597285068\n"
     ]
    }
   ],
   "source": [
    "dbscan = cluster.DBSCAN(eps=20,min_samples = 1).fit(vectors)\n",
    "\n",
    "acc3 = np.mean(np.equal(dbscan.labels_, y))\n",
    "print('DBSCAN score is',acc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affinity score is 0.007918552036199095\n"
     ]
    }
   ],
   "source": [
    "affinity_propagation = cluster.AffinityPropagation().fit(vectors)\n",
    "acc4 = np.mean(np.equal(affinity_propagation.labels_, y))\n",
    "print('Affinity score is', acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agglomerative score is 0.9994343891402715\n"
     ]
    }
   ],
   "source": [
    "average_linkage = cluster.AgglomerativeClustering(n_clusters=2,linkage='average').fit(vectors)\n",
    "acc5 = np.mean(np.equal(average_linkage.labels_, y))\n",
    "print('Agglomerative score is',acc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birch score is 0.7618778280542986\n"
     ]
    }
   ],
   "source": [
    "birch = cluster.Birch(n_clusters=2).fit(vectors)\n",
    "acc6 = np.mean(np.equal(birch.labels_, y))\n",
    "print('Birch score is',acc6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianMixture best score is 1.0\n"
     ]
    }
   ],
   "source": [
    "gmm = mixture.GaussianMixture(n_components=2)\n",
    "\n",
    "parameters = {'covariance_type': ['full','diag','spherical'],\n",
    "             \n",
    "             }\n",
    "clf = GridSearchCV(gmm, parameters)\n",
    "clf.fit(vectors)\n",
    "\n",
    "cov = clf.best_params_['covariance_type']\n",
    "\n",
    "gmm = mixture.GaussianMixture(covariance_type=cov).fit(vectors)\n",
    "acc8 = np.mean(np.equal(gmm.predict(vectors), y))\n",
    "print('GaussianMixture best score is', acc8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
